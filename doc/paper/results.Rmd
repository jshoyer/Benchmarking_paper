---
title: "Results"
author: "JT McCrone"
date: "Febuary 2, 2016"
output: pdf_document
---
```{r.message=F,echo=F}
xamp_roc<-"figure 1"
miseq<-"figure 2"
Miseq<-"Figure 2"
hiseq<-"figure 3"
Hiseq<-"Figure 3"
qual<-"figure 4"
Qual<-"Figure 4"
freq<-"figure 5"
Freq<-"Figure 5"
lower<-"figure 6"
Lower<-"Figure 6"
dups<-"figure 7"
Dups<- "Figure 7"

```

There are two major components to the accuracy of a variant caller. The first, sensitivity, describes how well a variant caller can identify variants that are known to be real. In other words what proportion of the true positives are found. A sensitivity of 1 indicates that all true positives are found. The second, specificity, measures how well a variant caller can correctly identify true negatives. For example, the influenza genome is roughly 13KB. There are 3  potential variant nucleotides at each position leaving a variant caller with about 39,000 potential variants that can be called. The vast majority of these potential variants will not be present in the starting population and are potential false positives. A variant caller that correctly identifies all potential false positives as true negatives has a specificity of 1. A perfect variant caller will have a sensitivity and specificity of 1. It will identify all true variants and only the true variants.

There is an obvious trade off between sensitivity and specificity. It may be the case that a variant caller has near perfect sensitivity, and  can find all the true positives in a sample. However, if in the process it has low specificity and identifies many false positives downstream analysis will be confounded. Conversely, a variant caller may have perfect specificity and identify no false positives; however, if in process it has low sensitivity and identifies only a few true positives it will have limited applications. 

The trade off between sensitivity and specificity can be represented as a receiver operator curve or ROC (`r xamp_roc`). An ROC plots the sensitivity of an assay along the y axis and 1-specificity along the x axis. To make a ROC for a variant caller one must test an assay on known data. The outcomes can then be stratified according to some metric that represents our belief that a given variant is real. Often this is a p value or quality score. Because the true variants are known, the sensitivity and specificity can be calculated at different cut offs (`r xamp_roc` A). These points are then used to construct the curve (`r xamp_roc` B). A perfect ROC in which all the true positives can be separated from all potential false positives is a right angle that follows the upper left perimeter of the plot and passes through the point (0,1).

DeepSNV has been previously benchmarked using small genomic regions involving minimal PCR. However, RNA viral samples require an RT-PCR step, and the accuracy of this variant caller was previously unknown under these conditions. To characterize the accuracy of our sequencing pipeline, two lab strains, WSN33 and PR8, that differ at roughly 500 positions, were mixed  to create known viral populations (`r miseq` A). Briefly, genomes were amplified separately in segment specific RT-PCR reactions. This was done to avoid biases in amplification that may skew frequency measurements towards one strain. Reconstituted DNA genomes were made by mixing these products at equimolar ratios. The WSN33 mix was then serially diluted into PR8. These mixtures were sequenced using 2x250 reads on an Illumina Miseq and variants were called using DeepSNV. 

Because these are defined mixtures and the 491 true variants are known it is possible to measure the accuracy of our sequencing pipeline. Although sensitivity decreases slightly with variant frequency, we were able to detect variants at 0.5% with high accuracy. `r Miseq` C summarizes the accuracy of the pipeline at a p value cut off of 0.01. _Something about the specificity_


Although our first benchmarking experiment validated our ability to accurately detect rare variants in influenza populations, the experiment was run under laboratory conditions. The virus populations found in patient derived samples are often less divergent than the two strains used, and provide much less input than samples grown in cell culture. To mimic these conditions, 20 single point mutants made in the WSN33 background were diluted into wild type at decreasing frequencies (`r hiseq` A). This yielded 5 samples containing 20 known variants at frequencies ranging from 5% to 0.2% all at a concentration of $10^5$ genomes/$\mu$l. These samples were diluted serially into viral media to give a range of inputs matching that seen in patient samples. These samples were then sequenced on an Illumina Hiseq and variants called using DeepSNV. Focusing on the $10^5$ genomes/$\mu$l samples we find that again sensitivity is proportional to variant frequency (`r hiseq` B and C). The fact that the sensitivity drops more dramatically than in our previous experiment is not surprising given the fact the the RNA input derived from cell culture samples is often orders of magnitude higher than that provided in this experiment. During library prep, a disproportionate amount of the 2.0% sample was lost and this likely accounts for the decreased sensitivity in the 2.0% sample relative to the 1.0% sample. In addition to a more drastic drop in sensitivity we found a much larger number of false positives at a p value cut off of 0.01 (`r hiseq` C). It should be noted that in all cases the specificity was greater than 99%. However, given the large number of potential false positives even a specificity of 99% results in well over 200 false variant calls. Initially it is tempting to increase specificity by simply applying a more stringent p value cut off. This would result in marching backwards towards the y axis along the ROCs in `r hiseq` B. However it is apparent from the `r hiseq` B that any increase in specificity would result in a drastic decrease in sensitivity. In other words, we require other means of separating true from false positives than simply the DeepSNV p value. _perhaps more details about the setup mimicing real world. such as the mRT-PCR_

In deep sequencing studies of viral diversity mapping quality and base quality cutoffs are often used to ensure that only the highest caliber sequencing data is used to call variants. Mapping quality refers to our confidence that a given read is mapped to the correct position in the genome while base quality estimates the likelihood that the base read by the sequencer is correct. In our initial analysis we masked bases that had a base quality score less than 30. We did not apply any mapping quality cut offs. `r Qual` A shows the distribution of the mean quality scores of the variants (p <0.01) present in the $10^5$ genomes/$\mu$l samples. In our case we find that while true and false positive variants can largely be separated by these metrics,  commonly used cut offs are not sufficient (dashed lines `r qual` A). Additionally, we found that in general false positives were biased near the ends of sequencing reads (`r qual` B). This is not surprising as it is well known that sequencing quality dips near the read end; however, recall that all bases with phred scores less than 30 were masked from our variant calling. In this case it seems that even high quality false positives are disproportionately called near the ends of reads, while true positives are called uniformly across the read resulting in an average read position near the middle of the read. _potential reasons for the bias? pcr errors in the lib step, locations in the genome..._

In the light of these quality distributions we applied a number of cut offs and drastically increased our specificity without sacrificing sensitivity (`r qual` C and D). For a variant to be considered in our analysis we required a mean mapping quality of 30, a mean phred score of 35, and an average read position within the middle 50% of the read length. In addition to accurately identifying the presence of expected variants DeepSNV was able to fairly accurately measure the frequency of these variants (`r freq`). However, while the median frequencies are near the expected values, there is a fair spread about each median, something that should be kept in mind when basing down stream analysis on frequency measurements.

Influenza patient samples vary in input levels by several orders of magnitude depending on a variety of factors ranging from biological such as day post infection to methodological such as how much mucus is collected on the swab. To ensure accuracy across a range of input levels we diluted our known mutant mixes serially into viral media. We found both decreases in sensitivity and specificity accompanied lower input samples (`r lower`). The decreased sensitivity is expected as the likelihood of detecting rare events decreases with sample size. The decreased specificity is most likely due to a greater dependence on RT-PCR to amplify our signal to detectable limits. Is it not surprising that an amplification of noise accompanies this dependence. However, our results do highlight the importance of controlling for input levels when comparing populations of RNA viruses. 

If RT-PCR errors are responsible for the decreased specificity found at lower input levels we would expect such errors to be controlled by processing the samples in duplicate. To test this hypothesis, a subset of the $10^4$ genomes/$\mu$l were run in duplicate. The 0.2% was not run as we expected a decrease in sensitivity would accompany this approach and had little hope of finding these rare variants. Two RT-PCR reactions were run from a new RNA prep. These samples were processed separately and sequenced on the same lane of an Illumina Hiseq. The aforementioned cut offs were applied and for a variant call to be considered it needed to be found in both duplicates. This drastically improved our specificity and brought it to a comparable level as the $10^5$ samples (`r dups`). Unexpectedly, an increase in sensitivity accompanied this sequencing run. This is most likely do to a cleaner library prep with less sample loss during size selection. 









