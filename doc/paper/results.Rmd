---
title: "Results"
author: "JT McCrone"
date: "Febuary 9, 2016"
output: word_document
---
```{r.message=F,echo=F}
xamp_roc<-"figure 1"
miseq<-"figure 2"
Miseq<-"Figure 2"
hiseq<-"figure 3"
Hiseq<-"Figure 3"
qual<-"figure 4"
Qual<-"Figure 4"
freq<-"figure 5"
Freq<-"Figure 5"
lofreq<-"Figure 6"
Lofreq<-"figure 6"
lower<-"figure 7"
Lower<-"Figure 7"
dups<-"figure 8"
Dups<- "Figure 8"
Table<-"Table 1"
table<-"table 1"
```
#### Accuracy


There are two major components to the accuracy of a variant caller, sensitivity and specificity. Sensitivity, describes how well a variant caller can identify variants that are known to be real and present in the viral population. A sensitivity of 1 indicates that all true positives are found. Specificity, on the other hand, measures how well a variant caller can correctly identify true negatives. For example, the influenza genome is slightly larger than 13Kb. There are 3  potential variant nucleotides at each genomic position leaving a variant caller with over 40,000 potential variants that can be called. The vast majority of these potential variants will not be present in the starting population. They will only be found as the result of a sequencing or RT-PCR error. A variant caller that correctly identifies all potential false positives as true negatives has a specificity of 1. A perfect variant caller will have a sensitivity and specificity of 1 meaning it identifies all of the true variants and nothing else.

There is an obvious trade off between sensitivity and specificity. It may be the case that a variant caller has near perfect sensitivity, and  can find all the true positives in a sample. However, if in the process it has low specificity and identifies many false positives, downstream analysis will be confounded (`r table`). Conversely, a variant caller may have perfect specificity and identify no false positives; however, if in process it has low sensitivity and identifies only a few true positives it will have limited applications. 

The trade off between sensitivity and specificity can be represented as a receiver operator curve or ROC (`r xamp_roc`). An ROC plots the sensitivity of an assay along the y axis and 1-specificity along the x axis. To make a ROC for a variant caller one must test the assay on known data. The outcomes can then be stratified according to some metric that represents our belief that a given variant is real. Often this is a p value or quality score. Because the true variants are known, the sensitivity and specificity can be calculated at different cut offs (`r xamp_roc` A). These points are then used to construct the curve (`r xamp_roc` B). A perfect ROC in which all the true positives can be separated from all potential false positives is a right angle that follows the upper left perimeter of the plot and passes through the point (0,1).

#### Initial accuracy

There is a seemingly endless supply of variant callers on the market today, and it is beyond the scope of this work to give a comprehensive comparison of their accuracy. Instead we focus our efforts towards robustly benchmarking one variant caller and highlighting a few means for improving accuracy. In the process we hope to stress the importance of robustly benchmarking any variant caller under the experimental conditions to which it is being applied. 

All variant callers attempt to distinguish true variants from errors by estimating  error rates across a given genome. These rates can take various metrics into account such as phred score, nucleotide position on a read, and the context of a given base call. The question then becomes is a putative variant found more often than would be expected given the applicable error rate. We have chosen DeepSNV as our variant caller of choice for this analysis. DeepSNV uses a clonal plasmid control to estimate an error rate for each possible nucleotide at each genomic position. The plasmid control contains is a clonal copy of the genome that is to be analyzed and is processed and sequenced in parallel with the test samples. Thus the plasmid control allows DeepSNV to account for any context specific errors that may appear during the sequencing process. DeepSNV has previously been benchmarked using a mixture of plasmids containing a 1.5Kb regions of the HIV pol gene. This process involved minimal PCR and was devoid of a reverse transcription step. Patient derived RNA viral samples require an RT-PCR step, and the accuracy of this variant caller was previously unknown under these conditions. To characterize the accuracy of DeepSNV in the context of our sequencing pipeline, two lab strains, WSN33 and PR8, were mixed at different frequencies to create known viral populations (`r miseq` A). Briefly, genomes were amplified separately in segment specific RT-PCR reactions. This was done to avoid biases in amplification that may skew frequency measurements towards one strain. Reconstituted cDNA genomes were made by mixing these products at equimolar ratios. The WSN33 mix was then serially diluted into PR8. These mixtures were sequenced using 2x250 reads on an Illumina Miseq and variants were called using DeepSNV. 

Because these are defined mixtures and the 491 true variants are known it is possible to measure the accuracy of our sequencing pipeline. `r Miseq` summarizes the accuracy of DeepSNV when applied to our experimental conditions. In the past DeepSNV was found to have a sensitivity of 86.0% and perfect specificity when applied to variants at 0.1%. Under our conditions  and with a slightly more stringent p value (p=0.01 versus p=0.05) we found a small decrease in both sensitivity and specificity when applied to variants at 0.63% (`r miseq` C). The  decrease in specificity is not surprising as our sequencing setup requires an error prone RT-PCR step. The drop in  sensitivity is likely due to the increased stringency expected when correcting for the number of test required to study a 13Kb region compared to the 1.5Kb region that was tested in the past. (_this can be tested_) It should also be noted that although the drop in specificity is small, 1 compared to 0.9983, the change in the number of false positives is fairly large (0 compared to 66). 

#### Realistic conditions

Although our first benchmarking experiment validated our ability to accurately detect rare variants in influenza populations, the experiment was run under relatively artificial conditions. The virus populations found in patient derived samples are expected to be less divergent than the two strains used, and provide much less input than samples grown in cell culture. To mimic these conditions, 20 single point mutants were made in the WSN33 background and were diluted into wild type at decreasing frequencies (`r hiseq` A). This yielded 5 samples containing 20 known variants at frequencies ranging from 5% to 0.2% at a concentration of $10^5$ genomes/$\mu$l. These samples were diluted serially into viral media down to $10^3$ genomes/$\mu$l. This matches the range of inputs found in patient samples. The samples were then sequenced on an Illumina Hiseq and variants called using DeepSNV. Focusing on the $10^5$ genomes/$\mu$l samples we find that again sensitivity is correlated with variant frequency (`r hiseq` B and C). The fact that the sensitivity drops more dramatically than in our previous experiment is not surprising given the fact the the RNA input derived from cell culture samples is often orders of magnitude higher than that provided in this experiment. During library prep, a disproportionate amount of the 2.0% sample was lost compared to the others, and this loss likely accounts for the decreased sensitivity in the 2.0% sample relative to the 1.0% sample. In addition to a more drastic drop in sensitivity we found a much larger number of false positives at a p value cut off of 0.01 (`r hiseq` C). It should be noted that in all cases the specificity was greater than 99%. However, given the large number of potential false positives in an influenza genome (>40,000) even a specificity of 99% results in well over 200 erroneous variant calls. The drop in specificity is likely due to the decease in input levels. In our experience samples grown in cell culture have at least $10^7$ genomes/$\mu$l. As the genomic input decreases, we are more and more reliant on RT-PCR to amplify the true positive "signal" to a detectable level. It is not surprising that is error prone method also amplifies the noise in the process. Initially it is tempting to increase specificity by simply applying a more stringent p value cut off. This would result in marching backwards towards the y axis along the ROCs in `r hiseq` B. However, it is apparent from  `r hiseq` B that any increase in specificity would result in a drastic decrease in sensitivity. It is clear from `r hiseq` that under experimental conditions the DeepSNV output alone is insufficient to accurately separate true positives from false positives.

In deep sequencing studies of viral diversity mapping quality and base quality cutoffs are often used to ensure that only the highest caliber sequencing data is used to call variants. Mapping quality refers to our confidence that a given read is mapped to the correct position in the genome while base quality estimates the likelihood that the base read by the sequencer is correct. In our initial analysis we masked bases that had a base quality score less than 30. We did not apply any mapping quality cut offs. `r Qual` A shows the distribution of the mean quality scores of the variants (p <0.01) present in the $10^5$ genomes/$\mu$l samples. In our case we find that while true and false positive variants can largely be separated by these metrics,  commonly used cut offs are not sufficient (dashed lines `r qual` A). Additionally, we found that in general false positives were biased near the ends of sequencing reads (`r qual` B). This is not surprising as it is well known that sequencing quality dips near the end of a read; however, recall that all bases with phred scores less than 30 were masked from our variant calling. In this case it seems that even high quality false positives are disproportionately called near the ends of reads, while true positives are called uniformly across the read resulting in an average read position near the middle of the read. (_do I need potential reasons for the bias? locations in the genome...)_

In the light of these quality distributions we applied a number of cut offs and drastically increased our specificity without sacrificing sensitivity (`r qual` C and D). For a variant to be considered in our analysis we required a mean mapping quality of 30, a mean phred score of 35, and an average read position within the middle 50% of the read length. _These cut offs were choosen as they ..._ By applying these quality controls we were able to greatly decrease the number of false positives from over 200 in many cases to an average of 9 without sacrificing a single true positive. We recognize that by applying cut offs after variants have been called we are treating potential variant bases more stringently than those matching the consensus sequence. However,because we are applying cut offs to mean quality scores and there are many more consensus bases than variant bases at each position, it is unlikely these biases have any noticable affect on our analysis. In addition to accurately identifying the presence of expected variants DeepSNV was able to  accurately measure the frequency of these variants (`r freq`). However, while the median frequencies are near the expected values, there is a fair spread about each median, something that should be kept in mind when basing down stream analysis on frequency measurements.

#### Lofreq

In addition to DeepSNV, we analyzed our $10^5$ genomes/$\mu$l influenza populations with the variant caller Lofreq. This was done to ensure that the decreased accuracy that accompanied our realistic experimental conditions was not simply based on the DeepSNV variant calling method. Lofreq had marginally decreased sensitivity compared DeepSNV when applied to the variant frequencies $\geq$ 1.0% but marginally increased sensitivity when applied to variant frequencies $\l$ 1.0% (`r lofreq`). Additionally, Lofreq had specificity near that seen in our cell culture benchmarking experiment, and much better than DeepSNV prior to our quality controls. This is not completely surprising as the Lofreq algorithm takes MapQ and Phred scores into account when calling variants, something DeepSNV does not do. Additionally, Lofreq was not prone to calling false positives near the ends of reads, _(verify whether or not it uses read position Show distributions of Lofreq variants?)_, but   `r lofreq` A suggests that sacrificing sensitivity is the only means of increasing specificity.

Lofreq has been reported to have perfect specificity and a sensitivity of 96% for variants present at 0.2%. However, this accuracy reflects a best case scenario using simulated sequencing reads. As was the case with DeepSNV, the accuracy of Lofreq was much lower when applied under conditions that often face virologist using patient derived samples. Our data suggests that is inappropriate to apply Lofreq or DeepSNV under diverse experimental conditions and expect the performance to be unaffected. 

It may be possible to further filter the putative variants called by Lofreq and achieve a similar accuracy to what was achieved using DeepSNV. However, because DeepSNV was much less computationally intensive, more user friendly _not sure if I can or should say that_, and capable of high accuracy, we continued to benchmark DeepSNV using the less concentrated samples from our dilution series.

_Include Lofreq in supplimentary?_

#### Lower input levels

Influenza patient samples vary in input concentration by several orders of magnitude and depend on a variety of factors often outside the control of a researcher (day of collection, volume of mucus collected ect.). To ensure accuracy across a range of input levels we diluted our known mutant mixes serially into viral media. We found both decreases in sensitivity and specificity accompanied lower input concentrations (`r lower`). The decreased sensitivity is expected as the likelihood of detecting rare events decreases with sample sizem while the decreased specificity is most likely due to a greater dependence on RT-PCR to amplify the signal to detectable limits. Is it not surprising that an amplification of noise accompanies this dependence. However, our results do highlight the importance of controlling for input levels when comparing populations of RNA viruses. 

If RT-PCR errors are responsible for the decreased specificity found at lower input levels, and RT_PCR are randomly distributed across the genome, we would expect such errors to be eliminated by processing the samples in duplicate. To test this hypothesis, a subset of the $10^4$ genomes/$\mu$l were run in duplicate. The 0.2% was not run as we expected a decrease in sensitivity would accompany this approach and had little hope of finding these rare variants based on the sensitivity we saw in `r lower` B. Two RT-PCR reactions were run from a new RNA prep. These samples were processed separately and sequenced on the same lane of an Illumina Hiseq. The previously mentioned quality cut offs were applied and for a variant call to be considered it was required to be found in both duplicates. This drastically improved our specificity and resulted an accuracy that was comparable to that found in the $10^5$ samples (`r dups`). Unexpectedly, an increase in sensitivity accompanied this sequencing run. This is most likely do to a superior library prep with less sample loss during size selection. 












