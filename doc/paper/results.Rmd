---
title: "Results"
author: "JT McCrone"
date: "Febuary 2, 2016"
output: pdf_document
---
```{r.message=F,echo=F}
xamp_roc<-"figure 1"
miseq<-"figure 2"
Miseq<-"Figure 2"
hiseq<-"figure 3"
Hiseq<-"Figure 3"
qual<-"figure 4"
Qual<-"Figure 4"
```

There are two major components to the accuracy of a variant caller. The first, sensitivity, describes how well a variant caller can identify variants that are known to be real. In other words what proportion of the true positives are found. A sensitivity of 1 indicates that all true positives are found. The second, specificity, measures how well a variant caller can correctly identify true negatives. For example, the influenza genome is roughly 13KB. There are 3  potential variant nucleotides at each position leaving a variant caller with about 39,000 potential variants that can be called. The vast majority of these potential variants will not be present in the starting population and are potential false positives. A variant caller that correctly identifies all potential false positives as true negatives has a specificity of 1. A perfect variant caller will have a sensitivity and specificity of 1. It will identify all true variants and only the true variants.

There is an obvious trade off between sensitivity and specificity. It may be the case that a variant caller has near perfect sensitivity, and  can find all the true positives in a sample. However, if in the process it has low specificity and identifies many false positives downstream analysis will be confounded. Conversely, a variant caller may have perfect specificity and identify no false positives; however, if in process it has low sensitivity and identifies only a few true positives again it will have limited applications. 

The trade off between sensitivity and specificity can be represented as a receiver operator curve or ROC (`r xamp_roc`). An ROC plots the sensitivity of an assay along the y axis and 1-specificity along the x axis. To make a ROC for a variant caller one must test an assay on known data. The outcomes can then be stratified according to some metric that represents our belief that a given variant is real. Often this is a p value or quality score. Because the true are known, the sensitivity and specificity can be calculated at various cut offs (`r xamp_roc` A). The points are used to construct the curve (`r xamp_roc` B). A perfect ROC in which all the true positives can be separated from all potential false positives is a right angle that follows the upper left perimeter of the plot and passes through the point (0,1).

DeepSNV has been previously benchmarked using small genomic regions involving minimal PCR. However, RNA viral samples require an RT-PCR step and the accuracy of this variant caller was previously unknown under these conditions. To characterize the accuracy of our sequencing pipeline, two lab strains, WSN33 and PR8, that differ at roughly 500 positions, were mixed  to create known viral populations (`r miseq` A). Briefly, genomes were amplified separately in segment specific RT-PCR reactions. This was done to avoid biases in amplification that may skew the down stream analysis. Reconstituted DNA genomes were made by mixing these products at equimolar ratios. The WSN33 mix was then serially diluted into PR8. These mixtures were sequenced using 2x250 reads on an Illumina Miseq and variants were called using DeepSNV. 

Because these are defined mixtures and the 491 true variants are known it is possible to measure the accuracy of our sequencing pipeline. Although sensitivity decreases slightly with variant frequency, we were able to detect variants at 0.5% with high accuracy. `r Miseq` C summarize the accuracy of the pipeline at a p value cut off of 0.01. _Something about the specificity_

Although our first benchmarking experiment validated our ability to accurately detect rare variants in influenza populations, the experiment was run under _adjective_ conditions. The virus populations found in patient derived samples are often less divergent than the two lab strains, and provide much less input than samples grown in cell culture. To mimic these conditions, 20 single point mutants made in the WSN33 background were diluted into wild type at decreasing frequencies (`r hiseq` A). This yielded 5 samples containing 20 known variants at frequencies ranging from 5% to 0.2% all at a concentration of $10^5$ genomes/$\mu$l. These samples were diluted serially into viral media to give a range of inputs matching that seen in patient samples. These samples were then sequenced on an Illumina Hiseq and variants called using DeepSNV. Focusing on the $10^5$ genomes/$\mu$l samples we find that again sensitivity is proportional to variant frequency (`r hiseq` B and C). The fact that the sensitivity drops more dramatically than in our previous experiment is not surprising given the fact the the RNA input derived from cell culture samples is often orders of magnitude higher than that provided in this experiment. During library prep, a disproportionate amount of the 2.0% sample was lost and this likely accounts for the decreased sensitivity in the 2.0% sample relative to the 1.0%. In addition to a more drastic drop in sensitivity we found a much larger number of false positives at a p value cut off of 0.01 (`r hiseq` C). It should be noted that in all cases the specificity was greater than 99%. However, given the large number of potential false positives even a specificity of 99% results in well over 200 false positives. Initially it is tempting to increase specificity by simply applying a more stringent p value cut off. This would result in marching backwards towards the y axis along the ROCs in `r hiseq` B. However it is apparent from the ROCs that any increase in specificity would result in a drastic decrease in sensitivity. In other words, we needed other means of separating true from false positives than simply the DeepSNV output.

In deep sequencing studies of viral diversity mapping quality and base quality cutoffs are often used to ensure that only the highest caliber sequencing data is used to call variants. Mapping quality refers to our confidence that a given read is mapped to the correct position in the genome while base quality estimates the likelihood that the base read by the sequencer is correct. In our initial analysis we masked bases that had a base quality score less than 30. We did not apply any mapping quality cut offs. `r Qual` A shows the distribution of the mean quality scores of the variants (p <0.01) present in the $10^5$ genomes/ $\mu$l samples. In our case we find that while true and false positive variants can largely be separated by these metrics, the commonly used cut offs are not sufficient (dashed lines `r qual` A). Additionally, we found that in general false positives were biased near the ends of sequencing reads (`r qual` B). This is not surprising as it is well known that sequencing quality dips near the read end; however, recall that all bases with phred scores less than 30 were masked from our variant calling. In this case is seems that even high quality false positives are disproportionately called near the ends of reads, while true positives are called uniformly across the read resulting in an average read position near the middle of the read. _potential reasons for the bias? pcr errors in the lib step, locations in the genome..._

In the light of these quality distributions we applied a number of cut offs and drastically increased our specificity without sacrificing sensitivity (`r qual` C and D). For a variant to be considered in our analysis we required a mean mapping quality of 30,a mean phred score of 35, and an  average read position within the middle 50% of the read length. 





