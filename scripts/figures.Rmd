---
title: "Figures"
author: "JT McCrone"
date: "December 30, 2015"
output: html_document
---

Here are the figures (or figure panels) we are thinking of using in the Benchmarking paper.  I will include my comments and decriptions on each and perhaps over time this will develop into the results section
```{r,settings_and_lib,echo=F,message=F,}
require(ggplot2)
require("plyr")
require("Biostrings")
require(reshape2)
require("pROC")
require(gridExtra)
theme_set(new = theme_classic(base_size=24))
require(knitr)
opts_chunk$set(fig.align = "center", warning = FALSE, echo = FALSE, fig.width = 10, 
    fig.height = 7,message=F)
```


## Figure 1 

The accuracy of variants callers is most appropiately described by the sensitivity and specificity of a the caller at a given qualtiy threshold.  The sensitivity of a caller is the proportion of true, known variants identified by the algorith. The specificty is the the propotion of false variants corrected ignored. There is a trade off between sensitivity and specificity.  One may be able to correctly identify all known variants from a data; however, if in doing the the algorithm identifies a large number of false positives then a sensitivity of 1 is of little use in practive. Conversly it is possible to increase the stringency of a caller to the point that it does not identify any erroneous variants however, if in doing so all the true variants are also removed, perfect specificity is of no use.  A reciever operator curve (ROC) is a common way of visualizing the trade off between sensitivity and specificity. The DeepSNV algorithm returns a p value for each called variant. Figure 1 A depicts the relationship between various p value thresholds, and the resulting ROC using a hypothetical data set.


### ROC skematic
```{r, roc_skematic}
set.seed(42) # make the figures reproducible
example<-data.frame(Condition=c(rep(x = c(TRUE,FALSE),each=20)),test=c(runif(20,-10,-4),runif(20,-6,0))) # Make a dataframe of T and F positives with random p values that favors a lower distribution for the TP
ex.roc<-roc(example$Condition~example$test) # make an ROC based on this data

cord<-coords(ex.roc,x="all") # get the coordinates of the ROC
cord.l<-melt(cord) # melt the coodinates for ease of plotting
cord.l<- mutate(cord.l,Id=c(0,head(as.numeric(rownames(cord.l))%/%3,-1))) # Add an Id so that the specificity and sensitivity at a given threshold can be groupled together

# Set an id column to group the threshold,specificity, and sensitivity together with the same number by integer division. I adjust with c(0, head ..., -1) since 3%/%3=1 but it should be grouped with the 0's.
roc.df<-dcast(cord.l,Id~Var1) # dcast into columns of threshold, specificity and sensitivity
roc.df<-roc.df[order(roc.df$sensitivity),] # So that the points connect nicely

#Helper function that gets the threshold and sensitivity from and roc at a given speceificity
helper.roc<-function(spec,roc.df){
  above.sense.cut<-subset(roc.df,specificity>=spec,select=c(threshold,specificity,sensitivity)) # get the points where specificity is above the cutoff
  sense.min<-min(above.sense.cut$specificity) # get the minimum of these to get as close to desired sensitivity as possible
  sense.cut<-subset(above.sense.cut,specificity==sense.min) # get all rows where sensitivity is at this point
  spec.max<-max(sense.cut$sensitivity) # but there can be different FPR for each TPR so here we maximize specificity
  output<-subset(sense.cut,sensitivity==spec.max)
}

plot.ex<-function(spec1,spec2,roc.df,distribution){ 
  cut1<-helper.roc(spec1,roc.df)#dataframe with the threshold,sensitivity and specificity at the given specificity
  cut2<-helper.roc(spec2,roc.df)
  output<-rbind(cut1,cut2)
  lines<-data.frame(sense=c(output$sensitivity,output$sensitivity,0,0), # make a data frame with the coordinates for the lines whicha re to be added
                    spec=c(0,0,1-output$specificity,1-output$specificity), # really 1-specificity
                    group=rep(c(spec1,spec2),times=3))
  
  #plot the roc
  roc.p<-ggplot(roc.df,aes(x=1-specificity,y=sensitivity))+geom_step(color="black",size=2)+xlab("1-Specificity")+ylab("Sensitivity")+theme(axis.title.y=element_text(vjust=1))
  roc.p<-roc.p+geom_line(data=lines,aes(x=spec,y=sense,color=as.factor(group)),size=c(1.5),lty=c(2))+scale_color_brewer(palette="Set1")
    
 roc.p<-roc.p+theme(axis.title.y = element_text(vjust=1.2))+theme(axis.title.x = element_text(vjust=0))+theme(legend.position="none")
  
 
 #plot the points and cut offs
 points.p<-ggplot(distribution,aes(x=1,y=test,fill=Condition))+geom_dotplot(binaxis = "y", stackdir = "center")+scale_fill_manual(values=c("white","black"),name="",breaks=c(T,F),labels=c("True Positive","False Positive"))+xlab("")+ylab("Log(p value)")+theme(axis.ticks = element_blank(), axis.text.x = element_blank(),axis.title.y = element_text(vjust=1.2))
 
 points.p<-points.p+geom_hline(yintercept=output$threshold,
                          size=1.5,lty=2,color=c("#e41a1c","#377eb8")) # these are the first 2 colors in set 1
  
 grid.arrange(points.p,roc.p,ncol=2)
 
}
plot.ex(0.35,0.95,roc.df,example)

pdf("../results/figures/roc.example.pdf")
plot.ex(0.35,0.95,roc.df,example)
dev.off()

```
### Experimental setup diagram

The accuracy of DeepSNV algorithm has been extensively benchmarked using a region of the HIV genome (?kb); however, we wanted to determine its accuracy in calling variants accross the entire influenza A genome ( 8 segments totally roughly 13kb).  To this end we diluted one lab strain WSN33 into another PR8 at decreasing frequencies. 491 single nucleotide variants were confirmed between these strains using sanger sequencing of plaque isolated samples.


### DeepSNV ROC 
```{r,roc_helper_runctions}
find_freq<-function(Id){ # helper function to get the expected frequency from the sample name
  if(Id=="Covaris_5"){
    x=0.05} else if ( Id=="Covaris_25"){
    x=0.025} else if ( Id=="Covaris_125"){
    x=0.0125} else if ( Id=="Covaris_063"){
    x=0.0063} else if ( Id=="Covaris_016"){
    x=0.0016}
}

find_freq.v<-Vectorize(find_freq) # vectorized version of the helper function above


id<-function(x){
  x<-strsplit(x,".",fixed=T)[[1]][1]
}

seg<-function (x) {
  x <- strsplit(x, ".", fixed = T)[[1]][2]
}  

fill_in_plots<-function(x){
  spec<-min(x$adj.specificity[which(x$adj.specificity>0.998)])
  sense<-max(x$adj.sensitivity[x$adj.specificity==spec]) # incase there is a step right here
  
  y<-data.frame(threshold=x$threshold[1],Id=x$Id[1],adj.specificity=0.9980001,adj.sensitivity=sense,samp=unique(x$samp),exp.freq=x$exp.freq[1],FP=x$FP[1],TP=x$TP[1],sensitivity=x$sensitivity[1],specificity=x$specificity[1])
  
  if("gc" %in% names(x)){
    y$gc=x$gc[1]
  }
  return(y)
}

sum_roc<-function(x){
  sum.df<-subset(x,category %in% c(TRUE,FALSE),select=c(category,p.val))# get the TRUE and false variant calls and p.vals
  if(length(which(sum.df$category==T))>0){ # filter out cases where there aren't any TP found
    if(length(which(sum.df$category==F))==0){
      sum.df<-rbind(sum.df,data.frame(category=F,p.val=1))
    }  
    roc(sum.df$category~sum.df$p.val,plot=F,CI=T)
  }
}

roc_df<-function(roc_analysis){ # get the coordinates and cut offs for all the points in the ROC object
  roc_analysis<-roc_analysis[unlist(lapply(roc_analysis,is.null))==F]
  all<-lapply(roc_analysis,coords,x="all")
  all.long<-lapply(all, melt) 
  all.long<-lapply(all.long, function(x){ 
    mutate(x, 
           Id=c(0,head(as.numeric(rownames(x))%/%3,-1))
    )
  }) # Set an id column to group the threshold,specificity, and sensitivity together with the same number by integer division. I adjust with c(0, head ..., -1) since 3%/%3=1 but it should be grouped with the 0's.
  roc.ls<-lapply(all.long,function(x) dcast(x,Id~Var1)) # dcast into columns of threshold, specificity and sensitivity
  roc.df<-do.call(rbind,roc.ls) # combine into data frame
  roc.df$samp<-unlist(lapply(rownames(roc.df),id)) # add sample id column
  
  mutate(roc.df, exp.freq=find_freq.v(samp))-> roc.df
}  

adjust.coords<-function(roc.df,sum.df,possible_tp,possible_vars){ # adjust the sensitivity and specificity called by pROC  
  samp<-roc.df$samp[1]
  samp.df<-subset(sum.df,Id==samp)
  sense.factor<-length(which(samp.df$category==T))/possible_tp
  TN.samp<-length(which(samp.df$category==F))
  mutate(roc.df,adj.sensitivity=sensitivity*sense.factor,FP=(TN.samp-TN.samp*specificity),TP=adj.sensitivity*possible_tp,adj.specificity=(possible_vars-possible_tp-FP)/((possible_vars-possible_tp)))
}

roc_df.one<-function(roc_analysis,thr){ # get the coordinates and cut offs for all the points in the ROC object
  roc_analysis<-roc_analysis[unlist(lapply(roc_analysis,is.null))==F]
  all<-lapply(roc_analysis,coords,x=thr,input="thr")

  #roc.ls<-lapply(all.long,function(x) dcast(x,Id~Var1)) # dcast into columns of threshold, specificity and sensitivity
  roc.df<-as.data.frame(do.call(rbind,all)) # combine into data frame
  roc.df$samp<-rownames(roc.df) # add sample id column
  
  mutate(roc.df, exp.freq=find_freq.v(samp))-> roc.df
} 
######### Miseq roc functions ##########
miseq.roc<-function(sum.df,possible_tp,possible_vars){ # A function to run the roc calculations and adjustments
  roc.ls<-dlply(sum.df,~Id,sum_roc)

  roc.df<-roc_df(roc.ls)
  

  roc.df.adj<-ddply(roc.df,~samp,adjust.coords,sum.df,possible_tp,possible_vars)
  
  roc.df.adj<-mutate(roc.df.adj,exp.freq=as.factor(find_freq.v(samp)))
  fills<-ddply(roc.df.adj,~samp,fill_in_plots) # take out these lines to not fill in the plots
  roc.df.adj<-rbind(fills,roc.df.adj) # here too
  roc.df.adj<-roc.df.adj[order(roc.df.adj$adj.sensitivity),]
  roc.df.adj$exp.freq <- factor(roc.df.adj$exp.freq, levels = rev(levels(roc.df.adj$exp.freq)))
  return(roc.df.adj)
}
miseq.roc.table<-function(sum.df,cut.off,possible_tp,possible_vars){
  roc.ls<-dlply(sum.df,~Id,sum_roc)
  roc.df<-roc_df.one(roc.ls,cut.off)
  roc.df.adj<-ddply(roc.df,~samp,adjust.coords,sum.df,possible_tp,possible_vars)
  roc.df.adj<-roc.df.adj[order(roc.df.adj$exp.freq,decreasing = T),]
  roc.table<-subset(roc.df.adj,select=c(exp.freq,adj.sensitivity,TP,adj.specificity,FP))
  return(roc.table)
}

# The ROC data only includes points there the sensitivity changes.  At this point I have limitted our analysis to variants with p<0.05. So the lines in some plots stop short. For the final draft I will not apply this cut off. Even in that future case this step may be need as the ROC data only includes points where the sensitivity changes.  For now   This function extents the lines by adding a data point at the specificity of 0.002 and appropriate sensitivity. At the most it hurts us as we do not increase sensitivity and it might , but I doubt it. Anyway it is of no concern as we only care about the p=0.01 case which is well contained before this extension is needed

######### Hiseq roc functions ##########
hiseq.roc<-function(sum.df,possible_tp,possible_vars){ # A function to run the roc calculations and adjustments
  roc.ls<-dlply(sum.df,~Id,sum_roc)

  roc.df<-roc_df(roc.ls)


  roc.df.adj<-ddply(roc.df,~samp,adjust.coords,sum.df,possible_tp,possible_vars)
  roc.df.adj<-roc.df.adj[order(roc.df.adj$adj.sensitivity),]
  mutate(roc.df.adj, gc = as.numeric(sub(pat,"\\1",samp)),
       exp.freq = sub(pat,"\\2",samp)
  )-> roc.df.adj
  fills<-ddply(roc.df.adj,~samp,fill_in_plots) # take out these lines to not fill in the plots
  roc.df.adj<-rbind(fills,roc.df.adj) # here too
  roc.df.adj$exp.freq<-as.character(roc.df.adj$exp.freq) # so that teh calculations below work since it is a factor here
  mutate(roc.df.adj,exp.freq=ifelse(test = grepl("0",exp.freq),yes=as.numeric(exp.freq)/1000,no = as.numeric(exp.freq)/100))->roc.df.adj
  roc.df.adj$exp.freq<-as.factor(roc.df.adj$exp.freq)
  roc.df.adj$exp.freq <- factor(roc.df.adj$exp.freq, levels = rev(levels(roc.df.adj$exp.freq)))
  return(roc.df.adj)
}

hiseq.roc.table<-function(sum.df,cut.off,possible_tp,possible_vars){
  roc.ls<-dlply(sum.df,~Id,sum_roc)
  roc.df<-roc_df.one(roc.ls,cut.off)
  roc.df.adj<-ddply(roc.df,~samp,adjust.coords,sum.df,possible_tp,possible_vars)
mutate(roc.df.adj, gc = as.numeric(sub(pat,"\\1",samp)),
       exp.freq = sub(pat,"\\2",samp)
)-> roc.df.adj

mutate(roc.df.adj,exp.freq=ifelse(test = grepl("0",exp.freq),yes=as.numeric(exp.freq)/1000,no = as.numeric(exp.freq)/100))->roc.df.adj
roc.df.adj<-roc.df.adj[order(roc.df.adj$exp.freq,decreasing = T),]
roc.table<-subset(roc.df.adj,select=c(gc,exp.freq,adj.sensitivity,TP,adj.specificity,FP))
return(roc.table)
}
```

The initial ROC of DeepSNV applied the viral dilutions above. Note for these analyses we only inlcude variants with p<0.05. I will extend this in the future. Doing so will extend the ROCs but will not change the results as we set a cut off of 0.01 at most in all the tables. 

> Uniform ROC axis?

```{r,Miseq_out_of_the_box}

sum.df<-read.csv("../data/process/2014-5-30/one.sided/Variants/all.sum.csv",stringsAsFactors=F,comment.char = '#')
  
true_snv<-read.csv("../data/reference/PR8_WSN33.csv",comment.char = '#') # read in a csv of the differences in PR8 and WSN33 as determined by sanger
true_snv<-subset(true_snv,Ref!="-" & Allele.1!="-") # remove any indels as we are not concerned with them here
mutate(true_snv,mutant=paste0(Name,"_",Ref,Ref.Pos,Allele.1))->true_snv #make a column that has names the variants as segment_ReferencePositionVariant
true_snv<-rename(true_snv,c("Name"="chr","Ref.Pos"="pos")) # rename the columns for use later
PR8_var<-read.csv("../data/reference/PR8_variants.csv",comment.char = "#") # read in differences between plasmid control on viral PR8 used in dilutions


mutate(PR8_var,mutant=paste0(Name,"_",Ref,Ref.Pos,Allele.1))->PR8_var #make a column that has names the variants as segment_ReferencePositionVariant
PR8_var<-rename(PR8_var,c("Name"="chr","Ref.Pos"="pos")) # rename the columns for use later  
sum.df<-mutate(sum.df,category=mutation %in% true_snv$mutant) # add Column for True and false variants to variant calls
sum.df$category[sum.df$mutation %in% PR8_var$mutant]<-"PR8" # id the variants found in PR8
sum.df<-mutate(sum.df,exp.freq=find_freq.v(Id)) # add the expected frequency of the true variants


# Get information about the regions we can investigate based on the primer sites


regions.bed <-read.csv("../data/reference/pr8_noprimingsites.bed.csv",stringsAsFactors = F,comment.char = "#")
regions.bed<-mutate(regions.bed,length=stop-start-1) #because the numbers in the csv are the inner most binding sites of the primers and represent the last positiions that cannot be interogated.

possible_vars<-sum(regions.bed$length)*3 # three possible variants/ position

# limit the PR8 and the true positive data.frames to those not excluded by the priming sites

primer.cut<-function(x){ # a helper function to do this
  chr<-unique(x$chr)
  start<-regions.bed$start[match(x$chr,regions.bed$chr)]
  stop<-regions.bed$stop[match(x$chr,regions.bed$chr)]
  
  subset(x,pos>start & pos<stop)
}
sum.df<-ddply(sum.df,~chr,primer.cut) # interogating only the sites within primer location removes 244 called variants for two sided and 406 for one sided test
true_snv<-ddply(true_snv,~chr,primer.cut) # interogating only the sites within primer location removes 8 potential true positive (491)
PR8_var<-ddply(PR8_var,~chr,primer.cut) # interogating only the sites within primer location removes 12 potential PR8 differences (15)



## These functions make an ROC by allowing pROC to calculate the positions based on only the variants that are provided, and then we adjust the senesitivity for with what we know.  For example if only 3 TP are found in one sample pROC will call that 100% Sensitivity but we will adjust it to 3/possible_tp and so forth.

tp<-unique(true_snv$mutant)
possible_tp<-length(tp)


m.roc.df<-miseq.roc(sum.df,possible_tp,possible_vars)

miseq.roc.p<-ggplot(m.roc.df,aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))

miseq.roc.p

# pdf("../results/figures/miseq_roc.one.sided.pdf")
# miseq.roc
# dev.off()

m.roc.table<-miseq.roc.table(sum.df,0.01,possible_tp,possible_vars)
knitr::kable(m.roc.table)

ggplot(subset(sum.df,p.val<0.01),aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)+geom_hline(yintercept=c(63,188))


ggplot(sum.df,aes(x=Read_pos,fill=category))+geom_histogram(position="dodge")




```

### With read position cut off 63 and 188

```{r}
read.df<-subset(sum.df,Read_pos>63 & Read_pos<188)
m.roc.df<-miseq.roc(read.df,possible_tp,possible_vars)

miseq.roc.p<-ggplot(m.roc.df,aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))#+scale_x_continuous(limits=c(0,0.002)

miseq.roc.p

# pdf("../results/figures/miseq_roc.one.sided.pdf")
# miseq.roc
# dev.off()

m.roc.table<-miseq.roc.table(read.df,0.01,possible_tp,possible_vars)
knitr::kable(m.roc.table)

ggplot(subset(sum.df,p.val<0.01),aes(x=Phred,y=MapQ,color=category))+geom_point(alpha=0.5)

rm(list = setdiff(ls(), lsf.str())) # remove all variables except the functions

```


## Figure 2

### Hiseq expermintal setup


To test our accuracy under conditions that more closely resemble those found in patient derived samples, 20 single point mutants were mixed and diluted into wild type decreasing frequencies. This mixtures were then diltued into viral media to yeild a spectrum of known variants at a range of input levels.

### ROC
Out of the box here is how we do for the $10^5$ sample.

```{r,hiseq_roc}
sum.df<-read.csv("../data/process/2015-6-23/Variants/all.sum.csv",stringsAsFactors = F,comment.char = "#") # reading in the variants from the pipeline output

# Getting genome lenght and segment information from the wsn33 fasta file
reference.fasta<-"../data/reference/wsn33_wt_plasmid.fa" 
segments <- fasta.seqlengths(reference.fasta)
regions.bed <- data.frame(chr = gsub("[ ].*","", names(segments)), start=12, stop=segments-13, row.names=NULL) # the univeral primers are 12 and 13 bp long
regions.bed<-mutate(regions.bed,chr=as.character(chr))

# The samples are named in the following format log(genome copy/ul)_expected frequency of variants We'll use that information here to get the gc# and exp.freq for each variant called

pat<-"([0-9]+)_([0-9]+)" 
mutate(sum.df, gc = sub(pat,"\\1",Id),
       exp.freq = sub(pat,"\\2",Id)
)-> sum.df
mutate(sum.df,exp.freq=ifelse(test = grepl("0",exp.freq),yes=as.numeric(exp.freq)/1000,no = as.numeric(exp.freq)/100))->sum.df

# Id the variants as T or F 
true_snv<-read.csv("../data/reference/mutant_id.csv",stringsAsFactor=F) # get the T variants
sum.df<-mutate(sum.df,category=mutation %in% true_snv$mutant) # add Column for True and false variants
wt1_mut<-subset(sum.df,Id=="WT1",select=mutation)
wt2_mut<-subset(sum.df,Id=="WT2",select=mutation)

wt_mut<-intersect(wt1_mut$mutation,wt2_mut$mutation)

length(wt_mut)
sum.df$category[sum.df$mutation %in% wt_mut]<-"wt"
sum.df<-subset(sum.df,!(grepl("WT",Id))) # remove the WT samples

possible_tp<-20 # there are 20 possible true positives in the mix
regions.bed<-mutate(regions.bed,length=stop-start-1) #because the numbers in the csv are the inner most binding sites of the primers and represent the last positiions that cannot be interogated.

possible_vars<-sum(regions.bed$length)*3 # three possible variants/ position


h.roc.df<-hiseq.roc(sum.df,possible_tp,possible_vars)

Hiseq.roc<-ggplot(subset(h.roc.df,gc==5),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002));Hiseq.roc

h.table.df<-hiseq.roc.table(sum.df,0.01,possible_tp,possible_vars)

knitr::kable(subset(h.table.df,gc==5))
```

## 3) Phred and MapQ filters

It is common practice to account for base and mapping quality scores when calling variants. While DeepSNV is agnostic towards mapping qualty our initial analysis masked any base that had a phred score less than 30. Here we show that by focusing our analysis to varaints that have average phred >35 and average mapping quality >30 we can increase specificity without decrease sensitivity.

> The first plot here is just to show you the distributions. p<0.01. We usually only look at this after the read cut off. But here you can see the cut offs to quite a bit, but do leave a bit to do. the cut offs of 30 and 35 can be adjusted as well. There must be a nice way to find the cutoffs algorithmically.

```{r, phred_mapq filter}
sig.df<-subset(sum.df,p.val<0.01)

ggplot(subset(sig.df,category %in% c(T,F)),aes(x=Phred,y=MapQ,color=category))+geom_point(alpha=0.5)+geom_hline(yintercept=30)+geom_vline(xintercept=35)+facet_wrap(~gc)

#ggplot(subset(sig.df,gc==5 & category %in% c(T,F)),aes(x=Phred,y=MapQ,color=category))+geom_point()

cut.df<-subset(sum.df,MapQ>30 & Phred>35)

h.cut.df<-hiseq.roc(cut.df,possible_tp,possible_vars)

ggplot(subset(h.cut.df,gc==5),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))


h.cut.table<-hiseq.roc.table(cut.df,0.01,possible_tp,possible_vars)

knitr::kable(subset(h.cut.table,gc==5))
```

This is still for p<0.01 and 10^5 genomes/ul viral transport media.

## Figure 4 

### Read Position

> Again the first plot is just to show the distribution is the significant variants that pass the map and prhed cutoff for all samples run.

```{r,read_pos}
# ggplot(sig.df,aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)
# ggplot(subset(sig.df,gc==5),aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)
# 
# ggplot(cut.df,aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)
# ggplot(subset(cut.df,gc==5),aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)

sig.cut.df<-subset(cut.df,p.val<0.01)

ggplot(sig.cut.df,aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)
# ggplot(subset(sig.cut.df,gc==5),aes(x=pos,y=Read_pos,color=category))+geom_point()+facet_wrap(~chr)


ggplot(subset(sig.cut.df,category %in% c(T,F) & gc==5),aes(x=Read_pos,fill=category))+geom_histogram(position='dodge')


cut.read.df<-subset(cut.df,Read_pos>32 & Read_pos<94)

h.cut.read.df<-hiseq.roc(cut.read.df,possible_tp,possible_vars)

ggplot(subset(h.cut.read.df,gc==5),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))


h.cut.read.table<-hiseq.roc.table(cut.read.df,0.01,possible_tp,possible_vars)
knitr::kable(subset(h.cut.read.table,gc==5))
```

Same as above just with an added read cut off at 32 and 94 (middle 50%). p<0.01

### Lofreq out of the box

```{r,lofreq}

lofreq.df<-read.csv("../data/process/2015-6-23/lofreq/all.removed.mapq_vcf.vcf_csv.csv")

lofreq.df$p.val<-lofreq.df$QUAL # to make the roc based on the quality scores given by lofreq


lofreq.roc<-hiseq.roc(cut.df,possible_tp,possible_vars)

ggplot(subset(lofreq.roc,gc==5),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity (adjusted)")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))



#lofreq claims no further monkey bussiness is needed to we'll just make a table with all its output
ddply(lofreq.df,~Id,summarize,gc=gc[1],exp.freq=exp.freq[1],TP=length(which(category==T)),FP=length(which(category==F)))->lofreq.table
lofreq.table<-lofreq.table[order(lofreq.table$exp.freq,decreasing = T),]

knitr::kable(subset(lofreq.table,gc==5,select=c(exp.freq,TP,FP)))

```

### Frequency accuracy

For p<0.01 with phred, mapq and read position cut off.
```{r, frequency_accuracy}
# Here we'll just be using 

## Frequency
cut.read.sig.df<-subset(cut.read.df,p.val<0.01)
medians<-ddply(subset(cut.read.sig.df,category==T ),~exp.freq+gc, summarize, median=median(freq.var))

# ac_freq<-ggplot(subset(sum.df,category==T),aes(x=exp.freq,y=freq.var,fill=as.factor(exp.freq)))+facet_wrap(~gc)

#cut.read.sig.df$exp.freq<-as.factor(cut.read.sig.df$exp.freq)
#cut.read.sig.df$exp.freq <- factor(cut.read.sig.df$exp.freq, levels = rev(levels(cut.read.sig.df$exp.freq)))

ac_freq<-ggplot(subset(cut.read.sig.df,category==T & gc=="5"),aes(x=exp.freq,y=freq.var,fill=factor(exp.freq,levels=rev(levels(as.factor(exp.freq))))))

ac_freq<-ac_freq+geom_dotplot(binaxis = "y", stackdir = "center",dotsize=1)+scale_fill_brewer(palette="Set1")

ac_freq<-ac_freq+scale_y_log10(limits=c(0.001,0.1),breaks=c(0.001,0.002,0.005,0.01,0.02,0.05,0.1))#+theme(axis.text.y = element_text(colour = c("red","chartreuse4","black","chocolate2","azure4","blue","black"),face="bold"))
ac_freq<-ac_freq+scale_x_log10(limits=c(0.001,0.1),breaks=c(0.001,0.002,0.005,0.01,0.02,0.050,0.1))#+theme(axis.text.x = element_text(colour = c("red","chartreuse4","black","chocolate2","azure4","blue","black"),face="bold"))
ac_freq<-ac_freq+geom_abline(intercept = 0, slope = 1,linetype=2,size=1)
ac_freq<-ac_freq+xlab("Expected Frequency")+ylab("Measured Frequency")+theme(legend.position="none")

ac_freq<-ac_freq+geom_point(data=subset(medians,gc=="5"),mapping=aes(x=exp.freq,y=median),shape=95,size=30)
ac_freq
```


## Figure 5 Lower inputs
### 10^4
```{r,roc_lower_inputs4}
ggplot(subset(h.cut.read.df,gc==4),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))

knitr::kable(subset(h.cut.read.table,gc==4))
```

### 10^3
```{r,roc_lower_inputs3}
ggplot(subset(h.cut.read.df,gc==3),aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))

knitr::kable(subset(h.cut.read.table,gc==3))
```

### Duplicates

```{r,duplicates}
sum.df<-read.csv("../data/process/2015-11-14/Variants/all.sum.csv",stringsAsFactors = F,comment.char = "#")
#sum.df<-read.csv("~/Box Sync/Lab_work/NGS/Benchmarking/data/2015-11-14/all.sum.csv")
pat<-"([0-9]+)_([0-9]+)"
mutate(sum.df, exp.freq = sub(pat,"\\1",Id),
       dup = as.numeric(sub(pat,"\\2",Id)),
)-> sum.df

sum.df<-subset(sum.df,Id!="PC") # remove the plasmid control that was run
mutate(sum.df,Id=paste(4,exp.freq,sep="_"),exp.freq=ifelse(test = grepl("0",exp.freq),yes=as.numeric(exp.freq)/1000,no = as.numeric(exp.freq)/100))->sum.df


sum.df<-mutate(sum.df,category=mutation %in% true_snv$mutant) # add Column for True and false variants
sum.df$category[sum.df$mutation %in% wt_mut]<-"wt"

cut.df<-subset(sum.df,Phred>35 & MapQ>30 & Read_pos<94 & Read_pos>32)

dups<-ddply(cut.df,~exp.freq+mutation,summarize,freq1=freq.var[1],freq2=freq.var[2],p.val1=p.val[1],p.val2=p.val[2],category=category[1],Id=Id[1])
dups$freq2[is.na(dups$freq2)]<-0
dups$p.val2[is.na(dups$p.val2)]<-1

dups<-mutate(dups,p.val=pmax(p.val1,p.val2))

dups<-subset(dups,p.val!=1)

dups.roc<-hiseq.roc(dups,possible_tp,possible_vars)

ggplot(dups.roc,aes(x=1-adj.specificity,y=adj.sensitivity))+geom_step(aes(color=exp.freq),size=2)+scale_color_brewer(palette = "Set1")+xlab("1-Specificity")+ylab("Sensitivity")+guides(color=guide_legend(title="Frequency"))+scale_y_continuous(limits=c(0,1))+scale_x_continuous(limits=c(0,0.002))


dups.table<-hiseq.roc.table(dups,0.01,possible_tp,possible_vars)
knitr::kable(subset(dups.table))

```

These are variants that pass mapq,phred, and read cut and p<0.01 in both samples.10^4

This is so much better than before. Is there really that much variability between runs? 

> tables are right but does the ROC make sense?

### Ordinations
```{r,eval=F}
# No wt variants for this work. I'll start with the out of the box data p<0.01

sig.df<-subset(sig.df,category!="wt" & freq.var>0.01 & exp.freq>0.005) # no need to look at the samples were we expect things to be less than 1%

# at this point I'm just taking the counts on the forward direction and assuming that everyone has the same coverage this will be adjusted later to take a subsample

dcast(sig.df,Id~mutation,value.var ="freq.var",fill = 0)->counts

sample.names<-counts$Id
row.names(counts)<-sample.names
counts<-(subset(counts,select=-c(Id)))
vare.dist<-vegdist(counts);vare.dist

NMDS<-metaMDS(vare.dist,trymax = 100)
stressplot(NMDS)

plot(NMDS)
orditorp(NMDS,display="sites",cex=1.25,air=0.01)


cut.read.sig.df<-subset(cut.read.sig.df,category!="wt" & freq.var>0.01 & exp.freq>0.005) # no need to look at the samples were we expect things to be less than 1%

# at this point I'm just taking the counts on the forward direction and assuming that everyone has the same coverage this will be adjusted later to take a subsample

dcast(cut.read.sig.df,Id~mutation,value.var ="freq.var",fill = 0)->counts

sample.names<-counts$Id
row.names(counts)<-sample.names
counts<-(subset(counts,select=-c(Id)))
vare.dist<-vegdist(counts);vare.dist

NMDS<-metaMDS(vare.dist,trymax = 100)
stressplot(NMDS)

plot(NMDS)
orditorp(NMDS,display="sites",cex=1.25,air=0.01)


```
